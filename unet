# unet_agent.py
import argparse
import json
import os
import random
import shutil
import stat
import time
from typing import Any, Dict, List, Optional, Tuple

import cv2
import numpy as np
import segmentation_models_pytorch as smp
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from scipy import ndimage
from skimage import measure
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm


# ====================== 安全删除目录 ======================
def safe_rmtree(path: str, retries: int = 3, delay: float = 0.3):
    if not os.path.exists(path):
        return
    def _on_error(func, p, exc_info):
        if os.path.exists(p):
            os.chmod(p, stat.S_IWRITE)
        try:
            func(p)
        except Exception:
            pass
    for i in range(retries):
        try:
            shutil.rmtree(path, onerror=_on_error)
            return
        except Exception as e:
            if i == retries - 1:
                raise
            time.sleep(delay)


def apply_random_augmentations(image: np.ndarray, mask: Optional[np.ndarray]) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    """Apply light-weight augmentations to improve generalisation without harming edge detail."""
    if mask is None:
        return image, mask

    # Horizontal flip
    if random.random() < 0.5:
        image = np.flip(image, axis=1)
        mask = np.flip(mask, axis=1)

    # Vertical flip
    if random.random() < 0.3:
        image = np.flip(image, axis=0)
        mask = np.flip(mask, axis=0)

    # 90-degree rotations to simulate orientation variance
    if random.random() < 0.25:
        k = random.choice([1, 2, 3])
        image = np.rot90(image, k).copy()
        mask = np.rot90(mask, k).copy()

    # Slight brightness and gamma adjustments help the model capture subtle boundaries
    if random.random() < 0.25:
        gamma = 1.0 + random.uniform(-0.2, 0.2)
        image = np.clip(np.power(image, gamma), 0.0, 1.0)

    if random.random() < 0.25:
        scale = 1.0 + random.uniform(-0.2, 0.2)
        shift = random.uniform(-0.05, 0.05)
        image = np.clip(image * scale + shift, 0.0, 1.0)

    image = np.ascontiguousarray(image)
    mask = np.ascontiguousarray(mask)
    return image, mask


# ====================== 数据集类 ======================
class SegDataset(Dataset):
    def __init__(self, img_dir, mask_dir, img_list, augment: bool = False):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_list = img_list
        self.augment = augment

    def __len__(self):
        return len(self.img_list)

    def __getitem__(self, idx):
        img_name = self.img_list[idx]
        img_path = os.path.join(self.img_dir, img_name)
        base = img_name.rsplit("_img.jpg", 1)[0] if "_img.jpg" in img_name else img_name.rsplit(".", 1)[0]
        mask_path = None
        if self.mask_dir:
            for suffix in ["_mask.jpg", "mask.jpg"]:
                cand = f"{base}{suffix}"
                cand_path = os.path.join(self.mask_dir, cand)
                if os.path.exists(cand_path):
                    mask_path = cand_path
                    break

        image = Image.open(img_path).convert("RGB").resize((256, 256))
        image = np.array(image, dtype=np.float32) / 255.0
        mask_np: Optional[np.ndarray] = None

        if mask_path and os.path.exists(mask_path):
            mask = Image.open(mask_path).convert("L").resize((256, 256), Image.NEAREST)
            mask_np = (np.array(mask, dtype=np.float32) / 255.0 > 0.5).astype(np.float32)
        elif self.mask_dir:
            mask_np = np.zeros((256, 256), dtype=np.float32)

        if self.augment and mask_np is not None:
            image, mask_np = apply_random_augmentations(image, mask_np)

        image_tensor = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)
        if mask_np is not None:
            mask_tensor = torch.tensor(mask_np, dtype=torch.float32).unsqueeze(0)
        else:
            mask_tensor = torch.zeros((1, 256, 256), dtype=torch.float32)

        return image_tensor, mask_tensor, img_name


# ====================== 中心区域提取 ======================
def clean_prediction(pred_np: np.ndarray, threshold: float = 0.5, min_area_ratio: float = 0.002,
                     max_components: int = 4) -> np.ndarray:
    binary = (pred_np > threshold).astype(np.uint8)
    if binary.sum() == 0:
        return binary

    labeled, num_features = ndimage.label(binary)
    if num_features == 0:
        return binary

    regions = sorted(measure.regionprops(labeled), key=lambda r: r.area, reverse=True)
    total_area = pred_np.shape[0] * pred_np.shape[1]
    min_area = max(1, int(total_area * min_area_ratio))

    refined = np.zeros_like(binary)

    for idx, region in enumerate(regions):
        if idx < max_components or region.area >= min_area:
            refined[labeled == region.label] = 1

    if refined.sum() == 0 and regions:
        refined[labeled == regions[0].label] = 1

    refined = ndimage.binary_fill_holes(refined).astype(np.uint8)
    kernel = np.ones((3, 3), np.uint8)
    refined = cv2.morphologyEx(refined, cv2.MORPH_CLOSE, kernel, iterations=1)
    refined = cv2.morphologyEx(refined, cv2.MORPH_OPEN, kernel, iterations=1)
    return refined


# ====================== Dice ======================
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.view(-1)
    y_pred_f = y_pred.view(-1)
    inter = (y_true_f * y_pred_f).sum()
    return (2. * inter + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)


class BCEDiceLoss(nn.Module):
    def __init__(self, dice_weight: float = 0.6, smooth: float = 1e-6, pos_weight: Optional[float] = None):
        super().__init__()
        self.dice_weight = float(np.clip(dice_weight, 0.0, 1.0))
        self.smooth = smooth
        if pos_weight is not None:
            self.register_buffer("pos_weight", torch.tensor([pos_weight], dtype=torch.float32))
        else:
            self.pos_weight = None

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        if self.pos_weight is not None:
            pos_weight = self.pos_weight.to(logits.device)
            bce = F.binary_cross_entropy_with_logits(logits, targets, pos_weight=pos_weight)
        else:
            bce = F.binary_cross_entropy_with_logits(logits, targets)

        probs = torch.sigmoid(logits)
        intersection = (probs * targets).sum(dim=(1, 2, 3))
        union = probs.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))
        dice_loss = 1 - ((2 * intersection + self.smooth) / (union + self.smooth))
        dice_loss = dice_loss.mean()

        weight = float(self.dice_weight)
        return (1.0 - weight) * bce + weight * dice_loss


def save_val_predictions(model, val_loader, save_dir, device):
    model.eval()
    pred_dir = os.path.join(save_dir, "val_preds", "preds")   # 正确路径
    orig_dir = os.path.join(save_dir, "val_preds", "orig")     # 正确路径
    gt_dir   = os.path.join(save_dir, "val_preds", "gt_masks") # 正确路径

    for d in [pred_dir, orig_dir, gt_dir]:
        if os.path.exists(d):
            safe_rmtree(d)
        os.makedirs(d, exist_ok=True)

    with torch.no_grad():
        for images, masks, names in tqdm(val_loader, desc="保存验证集预测", leave=False):
            images = images.to(device)
            outputs = model(images)
            preds = torch.sigmoid(outputs)
            pred_np = preds[0, 0].cpu().numpy()
            clean_pred = clean_prediction(pred_np)
            pred_img = (clean_pred * 255).astype(np.uint8)
            orig_name = names[0]
            clean_name = orig_name.replace("_img.jpg", ".jpg") if "_img.jpg" in orig_name else orig_name

            Image.fromarray(pred_img).save(os.path.join(pred_dir, f"pred_{clean_name}"))
            orig_img = (images[0].cpu().numpy().transpose(1,2,0) * 255).astype(np.uint8)
            Image.fromarray(orig_img).save(os.path.join(orig_dir, f"orig_{clean_name}"))
            gt_img = (masks[0, 0].cpu().numpy() * 255).astype(np.uint8)
            Image.fromarray(gt_img).save(os.path.join(gt_dir, f"mask_{clean_name}"))

    print(f"验证集预测已保存 → {pred_dir}")


# ====================== 主训练函数 ======================
def train_and_predict(args):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"使用设备: {device}")
    os.makedirs(args.save_dir, exist_ok=True)

    train_files = sorted([f for f in os.listdir(args.train_img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
    if not train_files:
        raise ValueError("训练集为空！")
    print(f"训练集: {len(train_files)} 张")

    train_dataset = SegDataset(
        args.train_img_dir,
        args.train_mask_dir,
        train_files,
        augment=not args.disable_augment
    )
    pin_memory = device.startswith("cuda")
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=pin_memory,
        persistent_workers=pin_memory and args.num_workers > 0,
    )

    val_loader = None
    if args.val_img_dir and os.path.exists(args.val_img_dir) and os.listdir(args.val_img_dir):
        val_files = sorted([f for f in os.listdir(args.val_img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
        print(f"验证集: {len(val_files)} 张")
        val_dataset = SegDataset(args.val_img_dir, args.val_mask_dir, val_files, augment=False)
        val_loader = DataLoader(
            val_dataset,
            batch_size=1,
            shuffle=False,
            num_workers=max(0, min(args.num_workers, 2)),
            pin_memory=pin_memory,
        )
    else:
        print("无验证集，跳过验证")

    test_img_dir = args.test_img_dir or os.path.join(args.save_dir, "empty_test", "images")
    test_mask_dir = args.test_mask_dir or os.path.join(args.save_dir, "empty_test", "masks")
    for d in [test_img_dir, test_mask_dir]:
        safe_rmtree(d)
        os.makedirs(d, exist_ok=True)
    dummy_path = os.path.join(test_img_dir, "dummy.jpg")
    if not os.path.exists(dummy_path):
        Image.new("RGB", (256, 256)).save(dummy_path)
    test_loader = DataLoader(SegDataset(test_img_dir, test_mask_dir, ["dummy.jpg"]), batch_size=1)

    encoder_weights = None if not args.encoder_weights or args.encoder_weights.lower() == "none" else args.encoder_weights
    model = smp.Unet(
        args.encoder_name,
        encoder_weights=encoder_weights,
        in_channels=3,
        classes=1,
    ).to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    criterion = BCEDiceLoss(dice_weight=args.dice_weight, pos_weight=args.pos_weight)
    use_amp = args.use_amp and device.startswith("cuda")
    scaler = GradScaler(enabled=use_amp)

    best_dice = 0.0
    best_model_path = os.path.join(args.save_dir, "best_model.pth")
    metrics_history = []

    print("开始训练...")
    for epoch in range(args.epoch):
        model.train()
        train_loss = 0.0
        for imgs, msks, _ in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]", leave=False):
            imgs, msks = imgs.to(device, non_blocking=pin_memory), msks.to(device, non_blocking=pin_memory)
            optimizer.zero_grad(set_to_none=True)

            with autocast(enabled=use_amp):
                outs = model(imgs)
                loss = criterion(outs, msks)

            loss_value = float(loss.detach().item())
            if use_amp:
                scaler.scale(loss).backward()
                if args.grad_clip > 0:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                if args.grad_clip > 0:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
                optimizer.step()

            train_loss += loss_value

        avg_dice = 0.0
        avg_precision = 0.0
        avg_recall = 0.0
        if val_loader:
            model.eval()
            dice_scores: List[float] = []
            precision_scores: List[float] = []
            recall_scores: List[float] = []
            with torch.no_grad():
                for imgs, msks, _ in val_loader:
                    imgs, msks = imgs.to(device), msks.to(device)
                    with autocast(enabled=use_amp):
                        outs = model(imgs)
                        preds = torch.sigmoid(outs)
                    pred_np = preds[0, 0].cpu().numpy()
                    clean = clean_prediction(pred_np)
                    pred_t = torch.tensor(clean, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)
                    if msks.max() > 0:
                        dice_scores.append(dice_coef(msks, pred_t).item())
                        y_true = msks.view(-1).detach().cpu().numpy()
                        y_pred = pred_t.view(-1).detach().cpu().numpy()
                        tp = np.logical_and(y_true == 1, y_pred == 1).sum()
                        fp = np.logical_and(y_true == 0, y_pred == 1).sum()
                        fn = np.logical_and(y_true == 1, y_pred == 0).sum()
                        precision_scores.append(tp / (tp + fp + 1e-6))
                        recall_scores.append(tp / (tp + fn + 1e-6))
            avg_dice = float(np.mean(dice_scores)) if dice_scores else 0.0
            avg_precision = float(np.mean(precision_scores)) if precision_scores else 0.0
            avg_recall = float(np.mean(recall_scores)) if recall_scores else 0.0

        mean_train_loss = train_loss / max(1, len(train_loader))
        print(f"Epoch {epoch+1}: Loss={mean_train_loss:.4f}, Val Dice={avg_dice:.4f}, Val Prec={avg_precision:.4f}, Val Rec={avg_recall:.4f}")
        metrics_history.append({
            "epoch": epoch + 1,
            "loss": round(mean_train_loss, 6),
            "dice": round(avg_dice, 6),
            "precision": round(avg_precision, 6),
            "recall": round(avg_recall, 6),
        })

        if avg_dice > best_dice:
            best_dice = avg_dice
            torch.save(model.state_dict(), best_model_path)
            print(f"  最佳模型更新 (Dice: {best_dice:.4f})")
            if val_loader:
                save_val_predictions(model, val_loader, args.save_dir, device)  # 每次都覆盖

    with open(os.path.join(args.save_dir, "metrics.json"), "w", encoding="utf-8") as f:
        json.dump(metrics_history, f, indent=4, ensure_ascii=False)

    model.load_state_dict(torch.load(best_model_path, map_location=device))
    model.eval()
    pred_dir = os.path.join(args.save_dir, "preds")
    orig_dir = os.path.join(args.save_dir, "orig")
    gt_dir   = os.path.join(args.save_dir, "gt_masks")
    for d in [pred_dir, orig_dir, gt_dir]:
        os.makedirs(d, exist_ok=True)

    with torch.no_grad():
        for imgs, msks, names in test_loader:
            imgs = imgs.to(device)
            outs = model(imgs)
            pred_np = torch.sigmoid(outs)[0,0].cpu().numpy()
            clean = clean_prediction(pred_np)
            pred_img = (clean * 255).astype(np.uint8)
            Image.fromarray(pred_img).save(os.path.join(pred_dir, "pred_dummy.jpg"))
            Image.fromarray((imgs[0].cpu().numpy().transpose(1,2,0)*255).astype(np.uint8)).save(os.path.join(orig_dir, "orig_dummy.jpg"))
            Image.fromarray((msks[0,0].cpu().numpy()*255).astype(np.uint8)).save(os.path.join(gt_dir, "mask_dummy.jpg"))

    print(f"\n任务完成！")
    print(f"  验证集预测 → {os.path.join(args.save_dir, 'val_preds', 'preds')}")
    print(f"  最佳模型 → {best_model_path}")
    print(f"  最佳 Dice: {best_dice:.4f}")

    return args.save_dir, best_dice


# ====================== CLI ======================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--lr", type=float, default=0.001)
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--epoch", type=int, default=5)
    parser.add_argument("--encoder_name", type=str, default="resnet50")
    parser.add_argument("--encoder_weights", type=str, default="imagenet")
    parser.add_argument("--dice_weight", type=float, default=0.6, help="Weight assigned to Dice loss component")
    parser.add_argument("--pos_weight", type=float, default=None, help="Positive class weight for BCE component")
    parser.add_argument("--weight_decay", type=float, default=1e-4)
    parser.add_argument("--grad_clip", type=float, default=0.0, help="Gradient clipping norm (0 disables)")
    parser.add_argument("--num_workers", type=int, default=0)
    parser.add_argument("--use_amp", action="store_true", help="Enable mixed-precision training when CUDA is available")
    parser.add_argument("--disable_augment", action="store_true", help="Disable training-time augmentations")
    parser.add_argument("--save_dir", type=str, required=True)
    parser.add_argument("--train_img_dir", type=str, required=True)
    parser.add_argument("--train_mask_dir", type=str, required=True)
    parser.add_argument("--val_img_dir", type=str, default=None)
    parser.add_argument("--val_mask_dir", type=str, default=None)
    parser.add_argument("--test_img_dir", type=str, default=None)
    parser.add_argument("--test_mask_dir", type=str, default=None)
    parser.add_argument("--train_size", type=int, default=None)

    args = parser.parse_args()
    train_and_predict(args)
